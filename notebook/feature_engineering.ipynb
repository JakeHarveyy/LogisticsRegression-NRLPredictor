{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRL Feature Engineering Pipeline\n",
    "\n",
    "This notebook transforms the raw NRL match data into a feature-rich, model-ready dataset. It follows a structured, multi-step process to engineer features related to team form, strength, and match context, while carefully preventing data leakage.\n",
    "\n",
    "**Objective:** To create a comprehensive `nrl_matches_final_model_ready.csv` file that will serve as the input for our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Foundational Data Cleaning & Setup\n",
    "\n",
    "This is the most critical first step. We perform essential cleaning and setup tasks:\n",
    "- **Load Data**: Ingest the raw CSV file.\n",
    "- **Date Conversion**: Convert the 'Date' column to a proper datetime format.\n",
    "- **Chronological Sort**: Sort the entire dataset by date. **This is crucial for all time-series feature engineering** to prevent looking into the future.\n",
    "- **Create Target Variable**: Engineer the `Home_Win` binary target variable.\n",
    "- **Create Margin**: Calculate the `Home_Margin` for performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading & Cleaning Data ---\n",
      "Loaded dataset: ../data/nrlBaselineData.csv\n",
      "Data cleaned and sorted. Shape: (3336, 26)\n",
      "Date range: 2009-03-13 to 2025-06-29\n",
      "Total matches: 3336\n",
      "Unique teams: 17\n",
      "Missing values per column:\n",
      "  Over Time?: 3210 (96.2%)\n",
      "  Home Odds: 3 (0.1%)\n",
      "  Draw Odds: 3 (0.1%)\n",
      "  Away Odds: 3 (0.1%)\n",
      "  temperature_c: 1 (0.0%)\n",
      "  wind_speed_kph: 1 (0.0%)\n",
      "  precipitation_mm: 1 (0.0%)\n",
      "\n",
      "Home team advantages:\n",
      "  Win rate: 0.569\n",
      "  Average margin: 2.99\n",
      "\n",
      "=== DATA PREVIEW (First 5 rows) ===\n",
      "      Date            Home Team         Away Team  Home Score  Away Score  Home_Win  Home_Margin  match_id temperature_category\n",
      "2009-03-13      Melbourne Storm St George Dragons          17          16         1            1         0                 warm\n",
      "2009-03-13     Brisbane Broncos North QLD Cowboys          19          18         1            1         1                 warm\n",
      "2009-03-14      Cronulla Sharks  Penrith Panthers          18          10         1            8         2                 warm\n",
      "2009-03-14 New Zealand Warriors   Parramatta Eels          26          18         1            8         3                 mild\n",
      "2009-03-14  Canterbury Bulldogs  Manly Sea Eagles          34          12         1           22         4                 warm\n",
      "\n",
      "=== DATA TYPES ===\n",
      "Date                    datetime64[ns]\n",
      "Home Team                       object\n",
      "Away Team                       object\n",
      "Home Score                       int64\n",
      "Away Score                       int64\n",
      "Home_Win                         int64\n",
      "Home_Margin                      int64\n",
      "match_id                         int64\n",
      "temperature_category            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def load_and_clean_nrl_data(filepath='../data/nrlBaselineData.csv'):\n",
    "    \"\"\"Load, clean, and sort the foundational NRL dataset.\"\"\"\n",
    "    print(\"--- Step 1: Loading & Cleaning Data ---\")\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"Loaded dataset: {filepath}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}\")\n",
    "        return None\n",
    "    \n",
    "    # Date Conversion and Sorting\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "    df = df.sort_values(by='Date').reset_index(drop=True)\n",
    "    \n",
    "    # Create Target and Margin\n",
    "    df['Home_Win'] = (df['Home Score'] > df['Away Score']).astype(int)\n",
    "    home_win_rate = df['Home_Win'].mean()\n",
    "    df['Home_Margin'] = df['Home Score'] - df['Away Score']\n",
    "    df['match_id'] = df.index\n",
    "\n",
    "    print(f\"Data cleaned and sorted. Shape: {df.shape}\")\n",
    "    print(f\"Date range: {df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Total matches: {len(df)}\")\n",
    "    print(f\"Unique teams: {len(set(df['Home Team'].unique()) | set(df['Away Team'].unique()))}\")\n",
    "    print(f\"Missing values per column:\")\n",
    "    for col in df.columns:\n",
    "        missing = df[col].isnull().sum()\n",
    "        if missing > 0:\n",
    "            print(f\"  {col}: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nHome team advantages:\")\n",
    "    print(f\"  Win rate: {home_win_rate:.3f}\")\n",
    "    print(f\"  Average margin: {df['Home_Margin'].mean():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def preview_data(df, n_rows=5):\n",
    "    \"\"\"\n",
    "    Preview the cleaned dataset\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== DATA PREVIEW (First {n_rows} rows) ===\")\n",
    "    key_columns = ['Date', 'Home Team', 'Away Team', 'Home Score', 'Away Score', \n",
    "                   'Home_Win', 'Home_Margin', 'match_id', 'temperature_category']\n",
    "    print(df[key_columns].head(n_rows).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n=== DATA TYPES ===\")\n",
    "    print(df[key_columns].dtypes)\n",
    "\n",
    "# Execute Step 1\n",
    "df_cleaned = load_and_clean_nrl_data()\n",
    "if df_cleaned is not None:\n",
    "    preview_data(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Team-Level Stats DataFrame\n",
    "\n",
    "To calculate rolling statistics for each team, we need to transform the data from a *match-centric* view to a *team-centric* view. We \"melt\" the DataFrame so that each match is represented by two rows: one for the home team and one for the away team.\n",
    "\n",
    "This structure makes it trivial to perform `groupby('team_name').rolling(...)` operations in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Creating Team-Level Stats ---\n",
      "Team-level data created. Shape: (6672, 12)\n",
      " Original matches: 3336\n",
      " Team records created: 6672 (should be 2x matches)\n",
      " Unique teams: 17\n",
      " Date range: 2009-03-13 to 2025-06-29\n",
      "\n",
      "=== TEAM PERFORMANCE SUMMARY ===\n",
      "Top 5 teams by win rate:\n",
      "                        Games_Played  Wins  Win_Rate  Avg_Points_For  Avg_Points_Against  Avg_Margin\n",
      "team_name                                                                                           \n",
      "Melbourne Storm                  431   303     0.703          24.608              15.316       9.292\n",
      "Penrith Panthers                 421   251     0.596          22.176              18.344       3.831\n",
      "Sydney Roosters                  425   245     0.576          22.984              19.275       3.708\n",
      "South Sydney Rabbitohs           420   230     0.548          23.129              20.581       2.548\n",
      "Brisbane Broncos                 416   221     0.531          21.534              21.195       0.339\n",
      "\n",
      "Bottom 5 teams by win rate:\n",
      "                      Games_Played  Wins  Win_Rate  Avg_Points_For  Avg_Points_Against  Avg_Margin\n",
      "team_name                                                                                         \n",
      "New Zealand Warriors           404   179     0.443          19.918              22.851      -2.933\n",
      "Dolphins                        64    28     0.438          24.609              23.828       0.781\n",
      "Newcastle Knights              406   166     0.409          19.064              22.958      -3.894\n",
      "Wests Tigers                   400   155     0.388          19.252              24.395      -5.142\n",
      "Gold Coast Titans              401   153     0.382          19.409              24.404      -4.995\n",
      "\n",
      "=== HOME vs AWAY ADVANTAGE ===\n",
      "        won  points_for  points_against  margin\n",
      "Away  0.431      19.603          22.591  -2.988\n",
      "Home  0.569      22.591          19.603   2.988\n",
      "\n",
      "=== TEAM STATS PREVIEW (First 10 rows) ===\n",
      "      Date            team_name  is_home             opponent  points_for  points_against  margin  won\n",
      "2009-03-13     Brisbane Broncos        1    North QLD Cowboys          19              18       1    1\n",
      "2009-03-13      Melbourne Storm        1    St George Dragons          17              16       1    1\n",
      "2009-03-13    North QLD Cowboys        0     Brisbane Broncos          18              19      -1    0\n",
      "2009-03-13    St George Dragons        0      Melbourne Storm          16              17      -1    0\n",
      "2009-03-14  Canterbury Bulldogs        1     Manly Sea Eagles          34              12      22    1\n",
      "2009-03-14      Cronulla Sharks        1     Penrith Panthers          18              10       8    1\n",
      "2009-03-14     Manly Sea Eagles        0  Canterbury Bulldogs          12              34     -22    0\n",
      "2009-03-14 New Zealand Warriors        1      Parramatta Eels          26              18       8    1\n",
      "2009-03-14      Parramatta Eels        0 New Zealand Warriors          18              26      -8    0\n",
      "2009-03-14     Penrith Panthers        0      Cronulla Sharks          10              18      -8    0\n",
      "\n",
      "=== TEAM STATS DATA TYPES ===\n",
      "Date              datetime64[ns]\n",
      "team_name                 object\n",
      "is_home                    int64\n",
      "opponent                  object\n",
      "points_for                 int64\n",
      "points_against             int64\n",
      "margin                     int64\n",
      "won                        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def create_team_level_stats(df):\n",
    "    \"\"\"Transform match-level data to team-level data.\"\"\"\n",
    "    print(\"\\n--- Step 2: Creating Team-Level Stats ---\")\n",
    "    home_df = df[['match_id', 'Date', 'Home Team', 'Home Score', 'Away Score', 'Home_Win','Venue', 'City']].copy()\n",
    "    home_df.rename(columns={'Home Team': 'team_name', 'Home Score': 'points_for', 'Away Score': 'points_against', 'Home_Win': 'won'}, inplace=True)\n",
    "    home_df['is_home'] = 1\n",
    "    home_df['opponent'] = df['Away Team']\n",
    "\n",
    "    away_df = df[['match_id', 'Date', 'Away Team', 'Home Score', 'Away Score', 'Home_Win','Venue', 'City']].copy()\n",
    "    away_df.rename(columns={'Away Team': 'team_name', 'Away Score': 'points_for', 'Home Score': 'points_against'}, inplace=True)\n",
    "    away_df['won'] = 1 - away_df['Home_Win']\n",
    "    away_df['is_home'] = 0\n",
    "    away_df['opponent'] = df['Home Team']\n",
    "    away_df = away_df.drop(columns=['Home_Win'])\n",
    "\n",
    "    team_stats_df = pd.concat([home_df, away_df], ignore_index=True)\n",
    "    team_stats_df = team_stats_df.sort_values(['Date', 'team_name']).reset_index(drop=True)\n",
    "    team_stats_df['margin'] = team_stats_df['points_for'] - team_stats_df['points_against']\n",
    "    team_stats_df['lost'] = 1 - team_stats_df['won']\n",
    "    \n",
    "    print(f\"Team-level data created. Shape: {team_stats_df.shape}\")\n",
    "    return team_stats_df\n",
    "\n",
    "def preview_team_level_stats(match_df, team_stats_df, team_name=None, n_rows=10):\n",
    "        # Data validation and summary\n",
    "    print(f\" Original matches: {len(match_df)}\")\n",
    "    print(f\" Team records created: {len(team_stats_df)} (should be 2x matches)\")\n",
    "    print(f\" Unique teams: {team_stats_df['team_name'].nunique()}\")\n",
    "    print(f\" Date range: {team_stats_df['Date'].min().strftime('%Y-%m-%d')} to {team_stats_df['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Team performance summary\n",
    "    team_summary = team_stats_df.groupby('team_name').agg({\n",
    "        'won': ['count', 'sum', 'mean'],\n",
    "        'points_for': 'mean',\n",
    "        'points_against': 'mean',\n",
    "        'margin': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    team_summary.columns = ['Games_Played', 'Wins', 'Win_Rate', 'Avg_Points_For', 'Avg_Points_Against', 'Avg_Margin']\n",
    "    team_summary = team_summary.sort_values('Win_Rate', ascending=False)\n",
    "    \n",
    "    print(f\"\\n=== TEAM PERFORMANCE SUMMARY ===\")\n",
    "    print(\"Top 5 teams by win rate:\")\n",
    "    print(team_summary.head().to_string())\n",
    "    \n",
    "    print(f\"\\nBottom 5 teams by win rate:\")\n",
    "    print(team_summary.tail().to_string())\n",
    "    \n",
    "    # Home vs Away performance\n",
    "    home_away_stats = team_stats_df.groupby('is_home').agg({\n",
    "        'won': 'mean',\n",
    "        'points_for': 'mean',\n",
    "        'points_against': 'mean',\n",
    "        'margin': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    home_away_stats.index = ['Away', 'Home']\n",
    "    print(f\"\\n=== HOME vs AWAY ADVANTAGE ===\")\n",
    "    print(home_away_stats.to_string())\n",
    "\n",
    "    if team_name:\n",
    "        preview_df = team_stats_df[team_stats_df['team_name'] == team_name].head(n_rows)\n",
    "        print(f\"\\n=== TEAM STATS PREVIEW: {team_name} (First {n_rows} games) ===\")\n",
    "    else:\n",
    "        preview_df = team_stats_df.head(n_rows)\n",
    "        print(f\"\\n=== TEAM STATS PREVIEW (First {n_rows} rows) ===\")\n",
    "    \n",
    "    key_columns = ['Date', 'team_name', 'is_home', 'opponent', 'points_for', \n",
    "                   'points_against', 'margin', 'won']\n",
    "    \n",
    "    print(preview_df[key_columns].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n=== TEAM STATS DATA TYPES ===\")\n",
    "    print(team_stats_df[key_columns].dtypes)\n",
    "\n",
    "# Execute Step 2\n",
    "team_stats_df = create_team_level_stats(df_cleaned)\n",
    "if team_stats_df is not None:\n",
    "    preview_team_level_stats(df_cleaned, team_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate Rolling \"Form\" Features\n",
    "\n",
    "This is where we quantify each team's recent performance, or \"form\". We use rolling windows to calculate moving averages for key metrics.\n",
    "\n",
    "\n",
    "**Crucial for preventing data leakage:** We use `.shift(1)` after every rolling calculation. This ensures that the features for a given match are calculated using data from *previous* matches only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 3: Calculating Rolling Form Features ---\n",
      " Rolling features calculated for windows: [3, 5, 8]\n"
     ]
    }
   ],
   "source": [
    "def calculate_rolling_features(team_stats_df):\n",
    "    \"\"\"Calculate rolling averages and streaks for each team.\"\"\"\n",
    "    print(\"\\n--- Step 3: Calculating Rolling Form Features ---\")\n",
    "    df = team_stats_df.copy().sort_values(['team_name', 'Date'])\n",
    "    windows = [3, 5, 8]\n",
    "\n",
    "    for window in windows:\n",
    "        df[f'rolling_avg_margin_{window}'] = df.groupby('team_name')['margin'].transform(lambda x: x.rolling(window, 1).mean().shift(1))\n",
    "        df[f'rolling_win_percentage_{window}'] = df.groupby('team_name')['won'].transform(lambda x: x.rolling(window, 1).mean().shift(1))\n",
    "        df[f'rolling_avg_points_for_{window}'] = df.groupby('team_name')['points_for'].transform(lambda x: x.rolling(window, 1).mean().shift(1))\n",
    "        df[f'rolling_avg_points_against_{window}'] = df.groupby('team_name')['points_against'].transform(lambda x: x.rolling(window, 1).mean().shift(1))\n",
    "        \n",
    "    print(f\" Rolling features calculated for windows: {windows}\")\n",
    "    return df\n",
    "\n",
    "# Execute Step 3\n",
    "team_stats_form = calculate_rolling_features(team_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "streaks features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning/Losing streaks calculated\n"
     ]
    }
   ],
   "source": [
    "def calculate_streaks(df):\n",
    "    \"\"\"\n",
    "    Calculate winning and losing streaks for each team\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_current_streak(series):\n",
    "        \"\"\"Calculate current win/loss streak from a boolean series\"\"\"\n",
    "        if len(series) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Shift to prevent data leakage - look at previous games only\n",
    "        shifted_series = series.shift(1)\n",
    "        \n",
    "        # Initialise streaks\n",
    "        winning_streak = []\n",
    "        losing_streak = []\n",
    "        \n",
    "        for i, won in enumerate(shifted_series):\n",
    "            if pd.isna(won):  # First game has no history\n",
    "                winning_streak.append(0)\n",
    "                losing_streak.append(0)\n",
    "                continue\n",
    "                \n",
    "            # Look backwards to count streak\n",
    "            current_win_streak = 0\n",
    "            current_loss_streak = 0\n",
    "            \n",
    "            # Count backwards from current position\n",
    "            for j in range(i-1, -1, -1):\n",
    "                if pd.isna(shifted_series.iloc[j]):\n",
    "                    break\n",
    "                    \n",
    "                if shifted_series.iloc[j] == 1:  # Win\n",
    "                    if current_loss_streak > 0:  # End of loss streak\n",
    "                        break\n",
    "                    current_win_streak += 1\n",
    "                else:  # Loss\n",
    "                    if current_win_streak > 0:  # End of win streak\n",
    "                        break\n",
    "                    current_loss_streak += 1\n",
    "            \n",
    "            winning_streak.append(current_win_streak)\n",
    "            losing_streak.append(current_loss_streak)\n",
    "        \n",
    "        return pd.Series(winning_streak, index=series.index), pd.Series(losing_streak, index=series.index)\n",
    "    \n",
    "    # Apply streak calculation to each team\n",
    "    streak_data = df.groupby('team_name')['won'].apply(get_current_streak)\n",
    "    \n",
    "    # Extract winning and losing streaks\n",
    "    df['winning_streak'] = 0\n",
    "    df['losing_streak'] = 0\n",
    "    \n",
    "    for team_name, (win_streaks, loss_streaks) in streak_data.items():\n",
    "        team_mask = df['team_name'] == team_name\n",
    "        df.loc[team_mask, 'winning_streak'] = win_streaks.values\n",
    "        df.loc[team_mask, 'losing_streak'] = loss_streaks.values\n",
    "    \n",
    "    print(\"Winning/Losing streaks calculated\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "team_stats_streaks = calculate_streaks(team_stats_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "games since win/loss, past 3 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games since last win/lost & 3 game form calculated\n"
     ]
    }
   ],
   "source": [
    "def calculate_games_since(df):\n",
    "    # Recent form (last 3 games) - more granular\n",
    "    df['recent_wins_3'] = (\n",
    "        df.groupby('team_name')['won']\n",
    "        .rolling(window=3, min_periods=1)\n",
    "        .sum()\n",
    "        .shift(1)\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    \n",
    "    # Games since last win/loss (simplified approach to avoid index issues)\n",
    "    df['games_since_win'] = 0\n",
    "    df['games_since_loss'] = 0\n",
    "    \n",
    "    for team in df['team_name'].unique():\n",
    "        team_mask = df['team_name'] == team\n",
    "        team_data = df[team_mask].copy()\n",
    "        team_data = team_data.sort_values('Date')\n",
    "        \n",
    "        games_since_win = []\n",
    "        games_since_loss = []\n",
    "        \n",
    "        for i in range(len(team_data)):\n",
    "            if i == 0:\n",
    "                games_since_win.append(0)\n",
    "                games_since_loss.append(0)\n",
    "                continue\n",
    "            \n",
    "            # Count games since last win\n",
    "            win_count = 0\n",
    "            win_found = False\n",
    "            for j in range(i-1, -1, -1):\n",
    "                if team_data.iloc[j]['won'] == 1:\n",
    "                    win_found = True\n",
    "                    break\n",
    "                win_count += 1\n",
    "            games_since_win.append(win_count if win_found else i)\n",
    "            \n",
    "            # Count games since last loss\n",
    "            loss_count = 0\n",
    "            loss_found = False\n",
    "            for j in range(i-1, -1, -1):\n",
    "                if team_data.iloc[j]['won'] == 0:\n",
    "                    loss_found = True\n",
    "                    break\n",
    "                loss_count += 1\n",
    "            games_since_loss.append(loss_count if loss_found else i)\n",
    "        \n",
    "        df.loc[team_mask, 'games_since_win'] = games_since_win\n",
    "        df.loc[team_mask, 'games_since_loss'] = games_since_loss\n",
    "    print(\"Games since last win/lost & 3 game form calculated\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "team_stats_games_since = calculate_games_since(team_stats_streaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preview engineered features, might delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FEATURE ENGINEERING SUMMARY ===\n",
      " Rolling features created: 12\n",
      " Streak features created: 2\n",
      " Form features created: 3\n",
      " Total new features: 17\n",
      "\n",
      "Rolling features: ['rolling_avg_margin_3', 'rolling_win_percentage_3', 'rolling_avg_points_for_3', 'rolling_avg_points_against_3', 'rolling_avg_margin_5', 'rolling_win_percentage_5', 'rolling_avg_points_for_5', 'rolling_avg_points_against_5', 'rolling_avg_margin_8', 'rolling_win_percentage_8', 'rolling_avg_points_for_8', 'rolling_avg_points_against_8']\n",
      "Streak features: ['winning_streak', 'losing_streak']\n",
      "Form features: ['recent_wins_3', 'games_since_win', 'games_since_loss']\n",
      "\n",
      "=== DATA LEAKAGE VALIDATION ===\n",
      "First game null values: 0/204\n",
      "Data leakage prevention:   PARTIAL - 17 teams have non-null values\n",
      "  Teams with issues: ['Brisbane Broncos', 'Canberra Raiders', 'Canterbury Bulldogs']...\n"
     ]
    }
   ],
   "source": [
    "# Data validation and summary\n",
    "rolling_features = [col for col in team_stats_games_since.columns if col.startswith('rolling_')]\n",
    "streak_features = [col for col in team_stats_games_since.columns if 'streak' in col]\n",
    "form_features = [col for col in team_stats_games_since.columns if col.startswith(('recent_', 'games_since_'))]\n",
    "\n",
    "all_new_features = rolling_features + streak_features + form_features\n",
    "\n",
    "print(f\"\\n=== FEATURE ENGINEERING SUMMARY ===\")\n",
    "print(f\" Rolling features created: {len(rolling_features)}\")\n",
    "print(f\" Streak features created: {len(streak_features)}\")\n",
    "print(f\" Form features created: {len(form_features)}\")\n",
    "print(f\" Total new features: {len(all_new_features)}\")\n",
    "\n",
    "print(f\"\\nRolling features: {rolling_features}\")\n",
    "print(f\"Streak features: {streak_features}\")\n",
    "print(f\"Form features: {form_features}\")\n",
    "\n",
    "\n",
    "print(f\"\\n=== DATA LEAKAGE VALIDATION ===\")\n",
    "# Sort by team and date to get actual first games\n",
    "df_sorted = team_stats_games_since.sort_values(['team_name', 'Date']).reset_index(drop=True)\n",
    "first_games = df_sorted.groupby('team_name').first()\n",
    "\n",
    "# Count null values in rolling features for first games\n",
    "null_count = first_games[rolling_features].isnull().sum().sum()\n",
    "total_first_games = len(first_games)\n",
    "expected_nulls = total_first_games * len(rolling_features)\n",
    "print(f\"First game null values: {null_count}/{expected_nulls}\")\n",
    "\n",
    "# Additional validation: check if any first game has non-null rolling features\n",
    "non_null_teams = []\n",
    "for team in first_games.index:\n",
    "    team_first_game = first_games.loc[team]\n",
    "    if not team_first_game[rolling_features].isnull().all():\n",
    "        non_null_teams.append(team)\n",
    "\n",
    "if len(non_null_teams) == 0:\n",
    "    print(f\"Data leakage prevention:  PASS - All teams have null rolling features in first game\")\n",
    "else:\n",
    "    print(f\"Data leakage prevention:   PARTIAL - {len(non_null_teams)} teams have non-null values\")\n",
    "    print(f\"  Teams with issues: {non_null_teams[:3]}...\")  # Show first 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Engineer Strength & Context Features\n",
    "\n",
    "Beyond recent form, we need to capture inherent team strength and the context of the match. We engineer three key features:\n",
    "\n",
    "### 4a. Elo Ratings\n",
    "A dynamic rating system that measures a team's strength relative to its opponents over time. A win against a strong opponent yields more Elo points than a win against a weak one.\n",
    "\n",
    "### 4b. Rest Days\n",
    "Calculates the number of days a team has had to rest since their last match. This is a proxy for fatigue.\n",
    "\n",
    "### 4c. Travel Distance\n",
    "Calculates the distance an away team has to travel from their home city to the match venue. This is a proxy for travel fatigue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initialised 17 teams with Elo rating: 1500\n",
      " Processed 3336 matches for Elo calculation\n",
      "\n",
      "=== ELO RATINGS SUMMARY ===\n",
      "Top 5 teams by final Elo rating:\n",
      "Melbourne Storm     1690.579852\n",
      "Penrith Panthers    1690.424673\n",
      "Canberra Raiders    1595.585283\n",
      "Sydney Roosters     1586.357830\n",
      "Cronulla Sharks     1554.568276\n",
      "\n",
      "Bottom 5 teams by final Elo rating:\n",
      "South Sydney Rabbitohs    1442.037831\n",
      "Parramatta Eels           1434.357528\n",
      "St George Dragons         1405.294746\n",
      "Gold Coast Titans         1350.946560\n",
      "Wests Tigers              1299.040547\n"
     ]
    }
   ],
   "source": [
    "def calculate_elo_ratings(team_stats_df, k_factor=20, initial_elo=1500):\n",
    "    # Initialize Elo ratings for all teams\n",
    "    teams = team_stats_df['team_name'].unique()\n",
    "    elo_ratings = {team: initial_elo for team in teams}\n",
    "    \n",
    "    print(f\" Initialised {len(teams)} teams with Elo rating: {initial_elo}\")\n",
    "    \n",
    "    # Create copy and sort by date\n",
    "    df = team_stats_df.copy()\n",
    "    df = df.sort_values(['Date', 'match_id']).reset_index(drop=True)\n",
    "    \n",
    "    # Add columns for pre-match Elo ratings\n",
    "    df['pre_match_elo'] = 0.0\n",
    "    \n",
    "    # Process each match (two rows at a time - home and away)\n",
    "    processed_matches = set()\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        match_id = row['match_id']\n",
    "        \n",
    "        # Skip if we've already processed this match\n",
    "        if match_id in processed_matches:\n",
    "            continue\n",
    "        \n",
    "        # Get both teams' records for this match\n",
    "        match_data = df[df['match_id'] == match_id]\n",
    "        \n",
    "        if len(match_data) != 2:\n",
    "            continue\n",
    "            \n",
    "        home_row = match_data[match_data['is_home'] == 1].iloc[0]\n",
    "        away_row = match_data[match_data['is_home'] == 0].iloc[0]\n",
    "        \n",
    "        home_team = home_row['team_name']\n",
    "        away_team = away_row['team_name']\n",
    "        \n",
    "        # Store pre-match Elo ratings\n",
    "        home_pre_elo = elo_ratings[home_team]\n",
    "        away_pre_elo = elo_ratings[away_team]\n",
    "        \n",
    "        # Update DataFrame with pre-match Elo\n",
    "        df.loc[df['match_id'] == match_id, 'pre_match_elo'] = df.loc[df['match_id'] == match_id, 'team_name'].map({\n",
    "            home_team: home_pre_elo,\n",
    "            away_team: away_pre_elo\n",
    "        })\n",
    "        \n",
    "        # Calculate expected scores using Elo formula\n",
    "        # Home field advantage: add 100 Elo points to home team\n",
    "        home_elo_adjusted = home_pre_elo + 100\n",
    "        away_elo_adjusted = away_pre_elo\n",
    "        \n",
    "        expected_home = 1 / (1 + 10**((away_elo_adjusted - home_elo_adjusted) / 400))\n",
    "        expected_away = 1 - expected_home\n",
    "        \n",
    "        # Actual results\n",
    "        home_won = home_row['won']\n",
    "        away_won = away_row['won']\n",
    "        \n",
    "        # Update Elo ratings\n",
    "        elo_ratings[home_team] += k_factor * (home_won - expected_home)\n",
    "        elo_ratings[away_team] += k_factor * (away_won - expected_away)\n",
    "        \n",
    "        processed_matches.add(match_id)\n",
    "    \n",
    "    print(f\" Processed {len(processed_matches)} matches for Elo calculation\")\n",
    "    \n",
    "    # Add final Elo ratings summary\n",
    "    final_elos = pd.Series(elo_ratings).sort_values(ascending=False)\n",
    "    print(f\"\\n=== ELO RATINGS SUMMARY ===\")\n",
    "    print(\"Top 5 teams by final Elo rating:\")\n",
    "    print(final_elos.head().to_string())\n",
    "    print(f\"\\nBottom 5 teams by final Elo rating:\")\n",
    "    print(final_elos.tail().to_string())\n",
    "    \n",
    "    return df\n",
    "\n",
    "team_stats_elo = calculate_elo_ratings(team_stats_games_since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 4b: Calculating Rest Days (Season-Aware) ===\n",
      "Calculating rest days within seasons (excluding off-season gaps)...\n",
      " Rest days calculated for all teams (within seasons only)\n",
      " Off-season gaps excluded: 292 records\n",
      " Valid rest day calculations: 6380 records\n",
      "\n",
      "=== REST DAYS STATISTICS (Season-Aware) ===\n",
      "Mean rest days: 7.9\n",
      "Median rest days: 7.0\n",
      "Min rest days: 4\n",
      "Max rest days: 73\n",
      "\n",
      "Most common rest periods:\n",
      "rest_days\n",
      "4.0        3\n",
      "5.0      591\n",
      "6.0     1526\n",
      "7.0     1698\n",
      "8.0     1129\n",
      "9.0      569\n",
      "10.0     151\n",
      "11.0      45\n",
      "\n",
      "=== SEASON BREAKDOWN ===\n",
      "Valid rest day calculations per season:\n",
      "season\n",
      "2009    370\n",
      "2010    386\n",
      "2011    386\n",
      "2012    386\n",
      "2013    386\n",
      "2014    386\n",
      "2015    386\n",
      "2016    386\n",
      "2017    386\n",
      "2018    386\n",
      "2019    386\n",
      "2020    322\n",
      "2021    386\n",
      "2022    386\n",
      "2023    408\n",
      "2024    409\n",
      "2025    239\n",
      "\n",
      "  Found 16 rest periods > 30 days:\n",
      "      Date           team_name  rest_days  season\n",
      "2020-05-28    Brisbane Broncos       69.0    2020\n",
      "2020-05-30    Canberra Raiders       70.0    2020\n",
      "2020-05-31 Canterbury Bulldogs       73.0    2020\n",
      "2020-05-30     Cronulla Sharks       70.0    2020\n",
      "2020-05-29   Gold Coast Titans       68.0    2020\n",
      "Note: These may be mid-season breaks or scheduling anomalies\n"
     ]
    }
   ],
   "source": [
    "def calculate_rest_days(df):\n",
    "    print(\"\\n=== STEP 4b: Calculating Rest Days (Season-Aware) ===\")\n",
    "    \n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['team_name', 'Date']).reset_index(drop=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Extract year to identify seasons\n",
    "    df['season'] = df['Date'].dt.year\n",
    "    df['rest_days'] = np.nan\n",
    "    \n",
    "    print(\"Calculating rest days within seasons (excluding off-season gaps)...\")\n",
    "    \n",
    "    # Calculate rest days for each team, respecting season boundaries\n",
    "    for team in df['team_name'].unique():\n",
    "        team_mask = df['team_name'] == team\n",
    "        team_data = df[team_mask].copy()\n",
    "        team_data = team_data.sort_values('Date').reset_index()\n",
    "        \n",
    "        # Calculate rest days between consecutive games\n",
    "        for i in range(1, len(team_data)):\n",
    "            current_season = team_data.iloc[i]['season']\n",
    "            previous_season = team_data.iloc[i-1]['season']\n",
    "            \n",
    "            if current_season == previous_season:\n",
    "                current_date = team_data.iloc[i]['Date']\n",
    "                previous_date = team_data.iloc[i-1]['Date']\n",
    "                rest_days_value = (current_date - previous_date).days\n",
    "                \n",
    "                # Apply data leakage prevention by using previous game's rest days\n",
    "                # (shift effect built into the logic)\n",
    "                if i >= 2:  # Need at least 2 previous games to prevent leakage\n",
    "                    df.loc[team_data.iloc[i]['index'], 'rest_days'] = rest_days_value\n",
    "            # If different seasons, leave as NaN (off-season gap ignored)\n",
    "    return df\n",
    "    \n",
    "def preview_rest_days(df):\n",
    "    valid_rest_days = df['rest_days'].dropna()\n",
    "    \n",
    "    print(f\" Rest days calculated for all teams (within seasons only)\")\n",
    "    print(f\" Off-season gaps excluded: {df['rest_days'].isna().sum()} records\")\n",
    "    print(f\" Valid rest day calculations: {len(valid_rest_days)} records\")\n",
    "    \n",
    "    if len(valid_rest_days) > 0:\n",
    "        rest_stats = valid_rest_days.describe()\n",
    "        print(f\"\\n=== REST DAYS STATISTICS (Season-Aware) ===\")\n",
    "        print(f\"Mean rest days: {rest_stats['mean']:.1f}\")\n",
    "        print(f\"Median rest days: {rest_stats['50%']:.1f}\")\n",
    "        print(f\"Min rest days: {rest_stats['min']:.0f}\")\n",
    "        print(f\"Max rest days: {rest_stats['max']:.0f}\")\n",
    "        \n",
    "        # Count of different rest periods\n",
    "        rest_counts = valid_rest_days.value_counts().sort_index()\n",
    "        print(f\"\\nMost common rest periods:\")\n",
    "        print(rest_counts.head(8).to_string())\n",
    "        \n",
    "        # Season analysis\n",
    "        season_counts = df.groupby('season')['rest_days'].count()\n",
    "        print(f\"\\n=== SEASON BREAKDOWN ===\")\n",
    "        print(\"Valid rest day calculations per season:\")\n",
    "        print(season_counts.to_string())\n",
    "        \n",
    "        # Check for any suspiciously long rest periods (potential issues)\n",
    "        long_rest = valid_rest_days[valid_rest_days > 30]\n",
    "        if len(long_rest) > 0:\n",
    "            print(f\"\\n  Found {len(long_rest)} rest periods > 30 days:\")\n",
    "            long_rest_matches = df[df['rest_days'] > 30][['Date', 'team_name', 'rest_days', 'season']]\n",
    "            print(long_rest_matches.head().to_string(index=False))\n",
    "            print(f\"Note: These may be mid-season breaks or scheduling anomalies\")\n",
    "        else:\n",
    "            print(f\"\\n All rest periods are within reasonable range (≤30 days)\")\n",
    "    else:\n",
    "        print(f\"\\n  No valid rest day calculations found\")\n",
    "    \n",
    "team_stats_rest = calculate_rest_days(team_stats_elo)\n",
    "if team_stats_rest is not None:\n",
    "    preview_rest_days(team_stats_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 4c: Calculating Travel Distance ===\n",
      " Travel distances calculated for away games\n",
      "\n",
      "=== TRAVEL DISTANCE STATISTICS ===\n",
      "Mean travel distance: 358.3 km\n",
      "Median travel distance: 28.5 km\n",
      "Max travel distance: 2630.6 km\n",
      "Min travel distance: 0.0 km\n",
      "\n",
      "Longest travel distances:\n",
      "      Date       team_name            Venue     City  travel_distance_km\n",
      "2009-09-05 Melbourne Storm Mt Smart Stadium Auckland         2630.638431\n",
      "2010-03-20 Melbourne Storm Mt Smart Stadium Auckland         2630.638431\n",
      "2011-06-26 Melbourne Storm Mt Smart Stadium Auckland         2630.638431\n",
      "2012-06-03 Melbourne Storm Mt Smart Stadium Auckland         2630.638431\n",
      "2013-07-28 Melbourne Storm Mt Smart Stadium Auckland         2630.638431\n"
     ]
    }
   ],
   "source": [
    "def calculate_travel_distance(team_stats_df):\n",
    "    print(\"\\n=== STEP 4c: Calculating Travel Distance ===\")\n",
    "    \n",
    "    # NRL team home cities (approximate coordinates)\n",
    "    team_locations = {\n",
    "        'Brisbane Broncos': (-27.4975, 153.0137),  # Brisbane\n",
    "        'North Queensland Cowboys': (-19.2590, 146.8169),  # Townsville  \n",
    "        'Gold Coast Titans': (-28.0167, 153.4000),  # Gold Coast\n",
    "        'New Zealand Warriors': (-36.8485, 174.7633),  # Auckland\n",
    "        'Melbourne Storm': (-37.8136, 144.9631),  # Melbourne\n",
    "        'Canberra Raiders': (-35.2809, 149.1300),  # Canberra\n",
    "        'Sydney Roosters': (-33.8688, 151.2093),  # Sydney\n",
    "        'South Sydney Rabbitohs': (-33.8688, 151.2093),  # Sydney\n",
    "        'St George Illawarra Dragons': (-34.4278, 150.8931),  # Wollongong\n",
    "        'Cronulla-Sutherland Sharks': (-34.0544, 151.1518),  # Cronulla\n",
    "        'Manly Sea Eagles': (-33.7969, 151.2841),  # Manly\n",
    "        'Parramatta Eels': (-33.8176, 151.0032),  # Parramatta\n",
    "        'Penrith Panthers': (-33.7506, 150.6934),  # Penrith\n",
    "        'Wests Tigers': (-33.8688, 151.2093),  # Sydney\n",
    "        'Canterbury Bulldogs': (-33.9173, 151.1851),  # Canterbury\n",
    "        'Newcastle Knights': (-32.9283, 151.7817),  # Newcastle\n",
    "        'Dolphins': (-27.4975, 153.0137),  # Brisbane (Redcliffe)\n",
    "    }\n",
    "    \n",
    "    # Common venue locations\n",
    "    venue_locations = {\n",
    "        'Suncorp Stadium': (-27.4648, 153.0099),  # Brisbane\n",
    "        'Queensland Country Bank Stadium': (-19.2598, 146.8181),  # Townsville\n",
    "        'Cbus Super Stadium': (-28.0024, 153.3992),  # Gold Coast\n",
    "        'AAMI Park': (-37.8255, 144.9816),  # Melbourne\n",
    "        'GIO Stadium Canberra': (-35.2447, 149.1014),  # Canberra\n",
    "        'Allianz Stadium': (-33.8878, 151.2273),  # Sydney\n",
    "        'Accor Stadium': (-33.8474, 151.0616),  # Sydney Olympic Park\n",
    "        'WIN Stadium': (-34.4056, 150.8841),  # Wollongong\n",
    "        'PointsBet Stadium': (-34.0481, 151.1394),  # Cronulla\n",
    "        '4 Pines Park': (-33.7742, 151.2606),  # Manly\n",
    "        'CommBank Stadium': (-33.8007, 150.9810),  # Parramatta\n",
    "        'BlueBet Stadium': (-33.7347, 150.6750),  # Penrith\n",
    "        'Leichhardt Oval': (-33.8821, 151.1589),  # Leichhardt\n",
    "        'McDonald Jones Stadium': (-32.9154, 151.7734),  # Newcastle\n",
    "        'Mt Smart Stadium': (-36.9278, 174.8384),  # Auckland\n",
    "        'Kayo Stadium': (-27.3644, 153.0486),  # Redcliffe\n",
    "    }\n",
    "    \n",
    "    def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "        \"\"\"Calculate distance between two points on Earth using Haversine formula\"\"\"\n",
    "        from math import radians, sin, cos, sqrt, asin\n",
    "        \n",
    "        # Convert to radians\n",
    "        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "        \n",
    "        # Haversine formula\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "        c = 2 * asin(sqrt(a))\n",
    "        \n",
    "        # Earth's radius in kilometers\n",
    "        r = 6371\n",
    "        \n",
    "        return c * r\n",
    "    \n",
    "    df = team_stats_df.copy()\n",
    "    \n",
    "    # Initialise travel distance column\n",
    "    df['travel_distance_km'] = 0.0\n",
    "    \n",
    "    # Calculate travel distance only for away teams\n",
    "    away_games = df[df['is_home'] == 0].copy()\n",
    "    \n",
    "    for idx, row in away_games.iterrows():\n",
    "        team_name = row['team_name']\n",
    "        venue = row['Venue']\n",
    "        \n",
    "        # Get team home location\n",
    "        if team_name in team_locations:\n",
    "            team_lat, team_lon = team_locations[team_name]\n",
    "        else:\n",
    "            # Default to Sydney for unknown teams\n",
    "            team_lat, team_lon = (-33.8688, 151.2093)\n",
    "        \n",
    "        # Get venue location (try exact match first, then partial match)\n",
    "        venue_lat, venue_lon = None, None\n",
    "        \n",
    "        # Exact match\n",
    "        if venue in venue_locations:\n",
    "            venue_lat, venue_lon = venue_locations[venue]\n",
    "        else:\n",
    "            # Partial match for similar venue names\n",
    "            for venue_key in venue_locations:\n",
    "                if venue_key.lower() in venue.lower() or venue.lower() in venue_key.lower():\n",
    "                    venue_lat, venue_lon = venue_locations[venue_key]\n",
    "                    break\n",
    "        \n",
    "        # Default to team's home city if venue not found\n",
    "        if venue_lat is None:\n",
    "            venue_lat, venue_lon = team_lat, team_lon\n",
    "        \n",
    "        # Calculate distance\n",
    "        distance = haversine_distance(team_lat, team_lon, venue_lat, venue_lon)\n",
    "        df.loc[idx, 'travel_distance_km'] = distance\n",
    "    \n",
    "    print(f\" Travel distances calculated for away games\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preview_travel_distance(df):\n",
    "    # Summary statistics\n",
    "    away_distances = df[df['is_home'] == 0]['travel_distance_km']\n",
    "    travel_stats = away_distances.describe()\n",
    "    \n",
    "    print(f\"\\n=== TRAVEL DISTANCE STATISTICS ===\")\n",
    "    print(f\"Mean travel distance: {travel_stats['mean']:.1f} km\")\n",
    "    print(f\"Median travel distance: {travel_stats['50%']:.1f} km\")\n",
    "    print(f\"Max travel distance: {travel_stats['max']:.1f} km\")\n",
    "    print(f\"Min travel distance: {travel_stats['min']:.1f} km\")\n",
    "    \n",
    "    # Show longest travels\n",
    "    longest_travels = df[df['travel_distance_km'] > 0].nlargest(5, 'travel_distance_km')\n",
    "    print(f\"\\nLongest travel distances:\")\n",
    "    travel_display = longest_travels[['Date', 'team_name', 'Venue', 'City', 'travel_distance_km']]\n",
    "    print(travel_display.to_string(index=False))\n",
    "\n",
    "team_stats_travel = calculate_travel_distance(team_stats_rest)\n",
    "if team_stats_travel is not None:\n",
    "    preview_travel_distance(team_stats_travel)\n",
    "\n",
    "team_stats_final = team_stats_travel.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Assemble Final Model-Ready DataFrame\n",
    "\n",
    "This is the final and most important step. We merge all the engineered team-level features back into our original match-level DataFrame.\n",
    "\n",
    "The key action here is creating **difference features** (e.g., `elo_diff`, `form_margin_diff_5`). Our model will learn from the *relative difference* in form and strength between the two competing teams, which is much more predictive than looking at each team's stats in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 5: Assembling Final Model-Ready DataFrame ---\n",
      "\n",
      "=== 5.2: Merging Back to Main DataFrame ===\n",
      " Merged home team features: (3336, 47)\n",
      " Merged away team features: (3336, 68)\n",
      "\n",
      "=== 5.3: Adding Market Features ===\n",
      "\n",
      "=== 5.4: Creating Difference Features ===\n",
      "Creating the critical difference features that compare home vs away teams...\n",
      " Elo difference calculated\n",
      " Form differences calculated for 3 windows (12 features)\n",
      " Streak and recency differences calculated (5 features)\n",
      " Contextual features (rest days, travel) already available\n"
     ]
    }
   ],
   "source": [
    "def assemble_final_model_ready_dataframe(df, team_stats_final):\n",
    "    print(\"\\n--- Step 5: Assembling Final Model-Ready DataFrame ---\")\n",
    "    \n",
    "    # Split features into home and away sets\n",
    "    home_stats_df = team_stats_final[team_stats_final['is_home'] == 1].copy()\n",
    "    away_stats_df = team_stats_final[team_stats_final['is_home'] == 0].copy()\n",
    "\n",
    "    # Select and rename feature columns\n",
    "    base_columns = ['match_id', 'Date', 'team_name', 'is_home', 'points_for', \n",
    "                   'points_against', 'won', 'opponent', 'Venue', 'City', 'margin', 'lost']\n",
    "    \n",
    "    feature_columns = [col for col in team_stats_final.columns if col not in base_columns]\n",
    "\n",
    "    home_rename = {col: f'home_{col}' for col in feature_columns}\n",
    "    home_features = home_stats_df[['match_id'] + feature_columns].rename(columns=home_rename)\n",
    "\n",
    "    away_rename = {col: f'away_{col}' for col in feature_columns}\n",
    "    away_features = away_stats_df[['match_id'] + feature_columns].rename(columns=away_rename)\n",
    "\n",
    "    print(\"\\n=== 5.2: Merging Back to Main DataFrame ===\")\n",
    "    # Start with original match dataframe\n",
    "    df_final = df.copy()\n",
    "\n",
    "    # Merge home team features\n",
    "    df_final = df_final.merge(home_features, on='match_id', how='left')\n",
    "    print(f\" Merged home team features: {df_final.shape}\")\n",
    "    \n",
    "    # Merge away team features\n",
    "    df_final = df_final.merge(away_features, on='match_id', how='left')\n",
    "    print(f\" Merged away team features: {df_final.shape}\")\n",
    "\n",
    "    print(\"\\n=== 5.3: Adding Market Features ===\")\n",
    "    \n",
    "    df_final['home_implied_prob'] = np.where(\n",
    "        df_final['Home Odds'].notna() & (df_final['Home Odds'] > 0),\n",
    "        1 / df_final['Home Odds'],\n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    df_final['away_implied_prob'] = np.where(\n",
    "        df_final['Away Odds'].notna() & (df_final['Away Odds'] > 0),\n",
    "        1 / df_final['Away Odds'], \n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    df_final['market_spread'] = df_final['home_implied_prob'] - df_final['away_implied_prob']\n",
    "\n",
    "    print(\"\\n=== 5.4: Creating Difference Features ===\")\n",
    "    print(\"Creating the critical difference features that compare home vs away teams...\")\n",
    "    \n",
    "    # 1. Strength Difference (Most Important)\n",
    "    df_final['elo_diff'] = df_final['home_pre_match_elo'] - df_final['away_pre_match_elo']\n",
    "    print(\" Elo difference calculated\")\n",
    "    \n",
    "    # 2. Form Differences (Rolling Averages)\n",
    "    windows = [3, 5, 8]\n",
    "    \n",
    "    for window in windows:\n",
    "        # Margin differences\n",
    "        df_final[f'form_margin_diff_{window}'] = (\n",
    "            df_final[f'home_rolling_avg_margin_{window}'] - \n",
    "            df_final[f'away_rolling_avg_margin_{window}']\n",
    "        )\n",
    "        \n",
    "        # Win rate differences  \n",
    "        df_final[f'form_win_rate_diff_{window}'] = (\n",
    "            df_final[f'home_rolling_win_percentage_{window}'] - \n",
    "            df_final[f'away_rolling_win_percentage_{window}']\n",
    "        )\n",
    "        \n",
    "        # Points for differences\n",
    "        df_final[f'form_points_for_diff_{window}'] = (\n",
    "            df_final[f'home_rolling_avg_points_for_{window}'] - \n",
    "            df_final[f'away_rolling_avg_points_for_{window}']\n",
    "        )\n",
    "        \n",
    "        # Points against differences\n",
    "        df_final[f'form_points_against_diff_{window}'] = (\n",
    "            df_final[f'home_rolling_avg_points_against_{window}'] - \n",
    "            df_final[f'away_rolling_avg_points_against_{window}']\n",
    "        )\n",
    "    \n",
    "    print(f\" Form differences calculated for {len(windows)} windows (12 features)\")\n",
    "    \n",
    "    # 3. Streak & Recency Differences\n",
    "    df_final['winning_streak_diff'] = df_final['home_winning_streak'] - df_final['away_winning_streak']\n",
    "    df_final['losing_streak_diff'] = df_final['home_losing_streak'] - df_final['away_losing_streak']\n",
    "    df_final['games_since_win_diff'] = df_final['home_games_since_win'] - df_final['away_games_since_win']\n",
    "    df_final['games_since_loss_diff'] = df_final['home_games_since_loss'] - df_final['away_games_since_loss']\n",
    "    df_final['recent_wins_3_diff'] = df_final['home_recent_wins_3'] - df_final['away_recent_wins_3']\n",
    "    \n",
    "    print(\" Streak and recency differences calculated (5 features)\")\n",
    "    print(\" Contextual features (rest days, travel) already available\")\n",
    "    return df_final\n",
    "\n",
    "df_model_ready = assemble_final_model_ready_dataframe(df_cleaned, team_stats_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final model ready data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FINAL FEATURE BREAKDOWN:\n",
      "   • Total columns: 89\n",
      "   • Strength features: 1 - ['elo_diff']\n",
      "   • Form difference features: 12\n",
      "   • Streak difference features: 5\n",
      "   • Contextual features: 3 - ['home_rest_days', 'away_rest_days', 'away_travel_distance_km']\n",
      "   • Market features: 3 - ['home_implied_prob', 'away_implied_prob', 'market_spread']\n",
      "   • CORE MODEL FEATURES: 28\n",
      "\n",
      " DATA QUALITY CHECK:\n",
      "   • form_margin_diff_3: 9 missing (0.3%)\n",
      "   • form_win_rate_diff_3: 9 missing (0.3%)\n",
      "   • form_points_for_diff_3: 9 missing (0.3%)\n",
      "   • form_points_against_diff_3: 9 missing (0.3%)\n",
      "   • form_margin_diff_5: 9 missing (0.3%)\n",
      "   • form_win_rate_diff_5: 9 missing (0.3%)\n",
      "   • form_points_for_diff_5: 9 missing (0.3%)\n",
      "   • form_points_against_diff_5: 9 missing (0.3%)\n",
      "   • form_margin_diff_8: 9 missing (0.3%)\n",
      "   • Elo difference correlation with wins: 0.268\n",
      "\n",
      " STEP 5 COMPLETE!\n",
      "   • Final dataset shape: (3336, 89)\n",
      "   • Ready for machine learning model training!\n"
     ]
    }
   ],
   "source": [
    "def preview_final_summary(df_final):\n",
    "    # Count different types of features\n",
    "    all_columns = df_final.columns.tolist()\n",
    "    \n",
    "    # Core model features\n",
    "    core_features = []\n",
    "    \n",
    "    # Strength features\n",
    "    strength_features = ['elo_diff']\n",
    "    \n",
    "    # Form difference features\n",
    "    form_diff_features = [col for col in all_columns if col.startswith('form_') and col.endswith('_diff_3') or col.endswith('_diff_5') or col.endswith('_diff_8')]\n",
    "    \n",
    "    # Streak difference features\n",
    "    streak_diff_features = [col for col in all_columns if col.endswith('_streak_diff') or col.endswith('_win_diff') or col.endswith('_loss_diff') or col.endswith('_wins_3_diff')]\n",
    "    \n",
    "    # Contextual features (absolute values)\n",
    "    contextual_features = ['home_rest_days', 'away_rest_days', 'away_travel_distance_km']\n",
    "    \n",
    "    # Market features\n",
    "    market_features = ['home_implied_prob', 'away_implied_prob', 'market_spread']\n",
    "\n",
    "    # Weather Features\n",
    "    weather_features = ['temperature_c', 'wind_speed_kph' ,'precipitation_mm', 'is_rainy,is_windy,temperature_category']\n",
    "    \n",
    "    core_features = strength_features + form_diff_features + streak_diff_features + contextual_features + market_features + weather_features\n",
    "    \n",
    "    print(f\" FINAL FEATURE BREAKDOWN:\")\n",
    "    print(f\"   • Total columns: {len(all_columns)}\")\n",
    "    print(f\"   • Strength features: {len(strength_features)} - {strength_features}\")\n",
    "    print(f\"   • Form difference features: {len(form_diff_features)}\")\n",
    "    print(f\"   • Streak difference features: {len(streak_diff_features)}\")\n",
    "    print(f\"   • Contextual features: {len(contextual_features)} - {contextual_features}\")\n",
    "    print(f\"   • Market features: {len(market_features)} - {market_features}\")\n",
    "    print(f\"   • CORE MODEL FEATURES: {len(core_features)}\")\n",
    "    \n",
    "    # Data quality check\n",
    "    print(f\"\\n DATA QUALITY CHECK:\")\n",
    "    \n",
    "    # Check core features for missing values\n",
    "    for feature in core_features[:10]:  # Check first 10 core features\n",
    "        if feature in df_final.columns:\n",
    "            missing_count = df_final[feature].isna().sum()\n",
    "            missing_pct = missing_count / len(df_final) * 100\n",
    "            if missing_count > 0:\n",
    "                print(f\"   • {feature}: {missing_count} missing ({missing_pct:.1f}%)\")\n",
    "    \n",
    "    # Correlation check for most important features\n",
    "    if 'elo_diff' in df_final.columns and 'Home_Win' in df_final.columns:\n",
    "        elo_corr = df_final['elo_diff'].corr(df_final['Home_Win'])\n",
    "        print(f\"   • Elo difference correlation with wins: {elo_corr:.3f}\")\n",
    "    \n",
    "    print(f\"\\n STEP 5 COMPLETE!\")\n",
    "    print(f\"   • Final dataset shape: {df_final.shape}\")\n",
    "    print(f\"   • Ready for machine learning model training!\")\n",
    "\n",
    "preview_final_summary(df_model_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Final Datasets\n",
    "\n",
    "The pipeline is complete. We save the final model-ready DataFrame to a new CSV file. This file will be the single source of truth for all subsequent model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 6: Saving Final Datasets ---\n",
      " Final dataset saved successfully to: ../data/nrl_matches_final_model_ready.csv\n",
      " Final team dataset saved successfully to: ../data/nrl_team_stats_final_complete.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 6: Saving Final Datasets ---\")\n",
    "\n",
    "final_match_path = '../data/nrl_matches_final_model_ready.csv'\n",
    "df_model_ready.to_csv(final_match_path, index=False)\n",
    "\n",
    "final_team_path = '../data/nrl_team_stats_final_complete.csv'\n",
    "team_stats_final.to_csv(final_team_path, index=False)\n",
    "\n",
    "print(f\" Final dataset saved successfully to: {final_match_path}\")\n",
    "print(f\" Final team dataset saved successfully to: {final_team_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
